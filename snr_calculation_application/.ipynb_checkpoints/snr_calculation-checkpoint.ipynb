{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9152dfe4-0bb8-4631-8ec6-ec387ecbdd8f",
   "metadata": {},
   "source": [
    "# SNR Calculation Application\n",
    "This is an application of my simulation environment to predict SNR values for the Lake Wheeler Road AERPAW Environment. The goal is to train a model or construct a lookup table so we can find SNR values from arbitrary position inside the Phase 1 Geofence to each of the 4 Base Stations (LW1-LW4). These SNR values will be used in the model we are deploying in the AERPAW AADM challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ae8def7-06cf-4d12-a9a1-56ea90a43ad2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Antenna' from 'sionna.rt' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEnvironmentFramework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Environment, UAV, GroundUser\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msionna\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PathSolver\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Computing the Bounding Box\u001b[39;00m\n",
      "File \u001b[1;32m~\\RL-AERPAW-DT\\RL-AERPAW-DT\\snr_calculation_application\\..\\src\\EnvironmentFramework.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mortools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cp_model\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msionna\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Antenna, AntennaArray\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msionna\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transmitter, Receiver\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# The Earth's gravitational acceleration in m/s^2\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Antenna' from 'sionna.rt' (unknown location)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.EnvironmentFramework import Environment, UAV, GroundUser\n",
    "from sionna.rt import PathSolver\n",
    "\n",
    "# Computing the Bounding Box\n",
    "LAUNCH = np.array([35.72752574530495, -78.69616739508318, 25])\n",
    "DELTA_LAT = 0.02  # Half of the bounding box height, in degrees\n",
    "DELTA_LON = 0.02 # Half of the bounding box width, in degrees\n",
    "BBOX = np.array([\n",
    "    [LAUNCH[0] - DELTA_LAT, LAUNCH[0] + DELTA_LAT],\n",
    "    [LAUNCH[1] - DELTA_LON, LAUNCH[1] + DELTA_LON]\n",
    "])\n",
    "\n",
    "# Guarantees a square bounding box with the launch point at the center\n",
    "# This is min/max latitude, and then min/max longitude to input into the Blender OSM Import\n",
    "print(BBOX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b6ff7c-26f2-4db3-8f46-996de57bc70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the environment, takes a while\n",
    "env = Environment(\"C:/Users/legoe/Blender/BlenderDataFiles/SNR_Calculation/lake_wheeler_road_aerpaw.xml\",\n",
    "                  \"C:/Users/legoe/Sumo/2024-10-04-09-05-18/simulated_final_person_new.csv\",\n",
    "                  time_step=1, ped_height=1.5, ped_rx=False, wind_vector=np.zeros(3))\n",
    "env.setTransmitterArray()\n",
    "env.setReceiverArray()\n",
    "env.scene.preview(show_devices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45cb936-1838-49d3-8629-01069b7d85fc",
   "metadata": {},
   "source": [
    "## Checking Materials\n",
    "When the data was exported, I tried to specify that the material be medium dry ground according to Sionna specifications. I am not entirely sure if this is the case, so we check it and correct it to the correct material if needed. The material is important because we want to consider ground reflection paths in addition to Line-Of-Sight paths. That is why we need ground topology and material data for Sionna to use for the ray tracing simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8cad92-7c7b-430c-900f-c0282b85ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for object in env.scene._scene_objects:\n",
    "    env.scene.get(object).radio_material = \"itu_medium_dry_ground\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e937c02-ed82-484f-b67a-c55885639852",
   "metadata": {},
   "source": [
    "## LatLon <-> Cartesian Conversion Functions\n",
    "These methods are used to exchange between a local coordinate system used by Sionna, and the spherical coordinate system used by AERPAW. It should assume the launch point as the origin for the local coordinate system. I will have to check the coordinate alignment of the imported Blender model, which was X forward and Z up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109cebed-601d-4434-a3af-4541df157d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 6371201  # Radius of Earth at Raleigh, in meters\n",
    "\n",
    "def latLonToCartesian(basis, lat_lon):\n",
    "    \"\"\"\n",
    "    Converts a series of points in lat_lon to points in cartesian with respect to the basis point in lat/lon\n",
    "    The height, which should be the third element of the points, is preserved\n",
    "\n",
    "    Args:\n",
    "        basis (np.array(float)): The lat/lon/height coordinates of the basis point, in degrees and meters\n",
    "        lat_lon (np.array(np.array(float))): The lat/lon/height coordinates of the points to convert, in degrees and meters\n",
    "\n",
    "    Returns:\n",
    "        np.array(np.array(float)): The x/y/z points in cartesian with respect to the basis point, in meters\n",
    "    \"\"\"\n",
    "\n",
    "    rtn = []\n",
    "    for i in range(len(lat_lon)):\n",
    "        rtn.append(cartesian(lat_lon[i], basis))\n",
    "    return np.array(rtn)\n",
    "\n",
    "\n",
    "def cartesianToLatLon(basis, coordinates):\n",
    "    rtn = []\n",
    "    for i in range(len(coordinates)):\n",
    "        rtn.append(latLon(coordinates[i], basis))\n",
    "    return np.array(rtn)\n",
    "\n",
    "\n",
    "def cartesian(lat_lon, basis):\n",
    "    \"\"\"\n",
    "    Converts a single point to lat/lon, with respect to the basis point\n",
    "    \"\"\"\n",
    "    return np.array([R * np.sin((lat_lon[0] - basis[0]) * np.pi / 180), \n",
    "                    R * np.sin((lat_lon[1] - basis[1]) * np.pi / 180), \n",
    "                    lat_lon[2]])\n",
    "    \n",
    "\n",
    "def latLon(coordinate, basis):\n",
    "    \"\"\"\n",
    "    Gets the lat/lon coordinate of a point with respect to the lat/lon basis point\n",
    "\n",
    "    Args:\n",
    "        coordinate (np.array()): The cartesian coordinate to convert in meters\n",
    "        basis (np.array()): The basis coordinate to use as a zero point, in lat/lon\n",
    "\n",
    "    Returns:\n",
    "        np.array(): the lat/lon coordinates of the point\n",
    "    \"\"\"\n",
    "    return np.array([np.asin(180 / (np.pi * R) * coordinate[0]) + basis[0],\n",
    "                     np.asin(180 / (np.pi * R) * coordinate[1]) + basis[1],\n",
    "                     coordinate[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc56f66-1ce2-471b-afd4-52daf5432757",
   "metadata": {},
   "source": [
    "## Modifying Receivers\n",
    "We want to get rid of the pedestrians in the scene, because they are not necessary to our current query of SNR data. We want to get our own receivers in the Sionna environment that line up with the positions of the base stations in the lake wheeler road AERPAW environment. This requires a bit of coordinate bashing and conversions but should be easily reconcilable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9d8a0-f8d2-4d41-b8b0-014703ef94eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground level is about 37 meters, so add this to the height of the receivers and UAVs\n",
    "GROUND_HEIGHT = 37\n",
    "\n",
    "BASE_STATIONS_LATLON = np.array([\n",
    "    [35.72750947, -78.69595810, 82.973],\n",
    "    [35.72821305, -78.70090823, 78.947],\n",
    "    [35.72491205, -78.69190014, 72.345],\n",
    "    [35.73318358, -78.6983642, 89.345]\n",
    "])\n",
    "\n",
    "BASE_STATIONS_LOCAL = latLonToCartesian(LAUNCH, BASE_STATIONS_LATLON)\n",
    "print(BASE_STATIONS_LOCAL)\n",
    "\n",
    "# Rotate 180 degrees for offset in the model\n",
    "for bs in BASE_STATIONS_LOCAL:\n",
    "    # bs[0] *= -1\n",
    "    bs[1] *= -1\n",
    "\n",
    "env.scene._transmitters.clear()\n",
    "env.scene._receivers.clear()\n",
    "base_stations = []\n",
    "for i in range(len(BASE_STATIONS_LOCAL)):\n",
    "    BASE_STATIONS_LOCAL[i][2] += GROUND_HEIGHT\n",
    "    g = GroundUser(i, np.array([BASE_STATIONS_LOCAL[i]]), height=BASE_STATIONS_LOCAL[i][2], com_type=\"tx\", delta_t=1)\n",
    "    base_stations.append(g)\n",
    "    env.scene.add(g.device)\n",
    "    \n",
    "env.gus = np.array(base_stations)\n",
    "env.scene.preview(show_devices=True)\n",
    "# This is verified as the correct orientation using the Blender model and validating it with the surrounding building data from OpenStreetMaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44746a2e-f5c4-445d-bae3-75f10856993e",
   "metadata": {},
   "source": [
    "## Adding UAV Device\n",
    "We will insert one UAV device, and then move it around the scene to different positions to record the SNR values there. We also need to account for any potential rotations in our import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee460e9-a8ae-4a19-90b0-cf7b8b1d281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.addUAV(0, pos=np.array([0, 0, 25 + GROUND_HEIGHT]), bandwidth=300)\n",
    "env.scene.preview(show_devices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8938969b-5222-42c2-93fe-20824b22dfcb",
   "metadata": {},
   "source": [
    "## Calculating SNR\n",
    "We now wish to set the UAV to a certain local position inside the simulation, and then compute the SNR values from that position to each of the base stations in the Lake Wheeler Road AERPAW environment. We change ALPHA to line up with AERPAW measurements, it is a compensation term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f53ad2-1997-4f9b-8695-8642c58173b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1.30 * 1e-23\n",
    "T = 290\n",
    "B = 24e8\n",
    "ALPHA = 10\n",
    "\n",
    "def computeSNR(uav_position):\n",
    "    env.moveAbsUAV(0, uav_position, np.zeros(3))\n",
    "    paths = env.scene.compute_paths(max_depth=2, method=\"fibonacci\", num_samples=1000000, los=True, reflection=True, diffraction=False, scattering=False, check_scene=False)\n",
    "    a, tau = paths.cir(los=True, reflection=True, diffraction=False, scattering=False, ris=False, sampling_frequency=B)\n",
    "    print(paths.sources)\n",
    "    a = tf.squeeze(a)\n",
    "    return 10 * tf.experimental.numpy.log10(ALPHA * tf.reduce_sum(tf.math.abs(a) ** 2, axis=1) / (k * T * B))\n",
    "\n",
    "res = computeSNR(np.array([0, 0, 25 + GROUND_HEIGHT]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3077c66-4a28-4439-995e-27102b0c219a",
   "metadata": {},
   "source": [
    "These results have one path for the reflection, and one for the LoS. The reflection is the second one that has the complex component. Now I just have to parse these alpha values into a combined SNR value between each base station and the UAV, then put it all together into a coherent function. \n",
    "\n",
    "## SNR Function\n",
    "We wish to sum the squared magnitudes of the alpha values for each path (there are only 2 for each base station in our case) then divide by the thermal noise power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf29c3-36cc-4655-ac63-339bb5b75f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Base Stations, 1 LoS and 1 Reflection each, so a 4x2 array\n",
    "print(res.shape)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf2d93-ec51-4fcc-9700-d261ff336c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which is Which?\n",
    "for receiver in env.scene._receivers:\n",
    "    print(env.scene.get(receiver).position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9c5d1-6d5d-47ce-822a-4f0124fca924",
   "metadata": {},
   "source": [
    "## Another Attempt\n",
    "This time I just want to use base Sionna, because my software is outdated to the most recent version of Sionna (1.0.2), and it would take a lot of effort to update everything in there. I believe that base Sionna has all the methods that I need, because I am not as concered about simulating pedestrian movement or power consumption, only SNR calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "405c5c1f-6373-4c52-b0a5-3d5e704b0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import sionna\n",
    "from sionna.rt import load_scene, PathSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e387bd4-2ee9-422c-bf86-d2479b57c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = load_scene(sionna.rt.scene.munich)\n",
    "# scene.preview(show_devices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9aaac0-dab1-4c92-a80a-bc226d8d11ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
