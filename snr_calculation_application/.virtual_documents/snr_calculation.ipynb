


import numpy as np
import tensorflow as tf
import sys
sys.path.append("..")
from src.EnvironmentFramework import Environment, UAV, GroundUser

# Computing the Bounding Box
LAUNCH = np.array([35.72752574530495, -78.69616739508318, 25])
DELTA_LAT = 0.02  # Half of the bounding box height, in degrees
DELTA_LON = 0.02 # Half of the bounding box width, in degrees
BBOX = np.array([
    [LAUNCH[0] - DELTA_LAT, LAUNCH[0] + DELTA_LAT],
    [LAUNCH[1] - DELTA_LON, LAUNCH[1] + DELTA_LON]
])

# Guarantees a square bounding box with the launch point at the center
# This is min/max latitude, and then min/max longitude to input into the Blender OSM Import
print(BBOX)


# Creating the environment, takes a while
env = Environment("C:/Users/legoe/Blender/BlenderDataFiles/SNR_Calculation/lake_wheeler_road_aerpaw.xml",
                  "C:/Users/legoe/Sumo/2024-10-04-09-05-18/simulated_final_person_new.csv",
                  time_step=1, ped_height=1.5, ped_rx=False, wind_vector=np.zeros(3))
env.setTransmitterArray()
env.setReceiverArray()
env.scene.preview(show_devices=False)





for object in env.scene._scene_objects:
    env.scene.get(object).radio_material = "itu_medium_dry_ground"





R = 6371201  # Radius of Earth at Raleigh, in meters

def latLonToCartesian(basis, lat_lon):
    """
    Converts a series of points in lat_lon to points in cartesian with respect to the basis point in lat/lon
    The height, which should be the third element of the points, is preserved

    Args:
        basis (np.array(float)): The lat/lon/height coordinates of the basis point, in degrees and meters
        lat_lon (np.array(np.array(float))): The lat/lon/height coordinates of the points to convert, in degrees and meters

    Returns:
        np.array(np.array(float)): The x/y/z points in cartesian with respect to the basis point, in meters
    """

    rtn = []
    for i in range(len(lat_lon)):
        rtn.append(cartesian(lat_lon[i], basis))
    return np.array(rtn)


def cartesianToLatLon(basis, coordinates):
    rtn = []
    for i in range(len(coordinates)):
        rtn.append(latLon(coordinates[i], basis))
    return np.array(rtn)


def cartesian(lat_lon, basis):
    """
    Converts a single point to lat/lon, with respect to the basis point
    """
    return np.array([R * np.sin((lat_lon[0] - basis[0]) * np.pi / 180), 
                    R * np.sin((lat_lon[1] - basis[1]) * np.pi / 180), 
                    lat_lon[2]])
    

def latLon(coordinate, basis):
    """
    Gets the lat/lon coordinate of a point with respect to the lat/lon basis point

    Args:
        coordinate (np.array()): The cartesian coordinate to convert in meters
        basis (np.array()): The basis coordinate to use as a zero point, in lat/lon

    Returns:
        np.array(): the lat/lon coordinates of the point
    """
    return np.array([np.asin(180 / (np.pi * R) * coordinate[0]) + basis[0],
                     np.asin(180 / (np.pi * R) * coordinate[1]) + basis[1],
                     coordinate[2]])





# Ground level is about 37 meters, so add this to the height of the receivers and UAVs
GROUND_HEIGHT = 37

BASE_STATIONS_LATLON = np.array([
    [35.72750947, -78.69595810, 82.973],
    [35.72821305, -78.70090823, 78.947],
    [35.72491205, -78.69190014, 72.345],
    [35.73318358, -78.6983642, 89.345]
])

BASE_STATIONS_LOCAL = latLonToCartesian(LAUNCH, BASE_STATIONS_LATLON)
print(BASE_STATIONS_LOCAL)

# Rotate 180 degrees for offset in the model
for bs in BASE_STATIONS_LOCAL:
    # bs[0] *= -1
    bs[1] *= -1

env.scene._transmitters.clear()
env.scene._receivers.clear()
base_stations = []
for i in range(len(BASE_STATIONS_LOCAL)):
    BASE_STATIONS_LOCAL[i][2] += GROUND_HEIGHT
    g = GroundUser(i, np.array([BASE_STATIONS_LOCAL[i]]), height=BASE_STATIONS_LOCAL[i][2], com_type="tx", delta_t=1)
    base_stations.append(g)
    env.scene.add(g.device)
    
env.gus = np.array(base_stations)
env.scene.preview(show_devices=True)
# This is verified as the correct orientation using the Blender model and validating it with the surrounding building data from OpenStreetMaps





env.addUAV(0, pos=np.array([0, 0, 25 + GROUND_HEIGHT]), bandwidth=300)
env.scene.preview(show_devices=True)





k = 1.30 * 1e-23
T = 290
B = 24e8
ALPHA = 10

def computeSNR(uav_position):
    env.moveAbsUAV(0, uav_position, np.zeros(3))
    paths = env.scene.compute_paths(max_depth=2, method="fibonacci", num_samples=1000000, los=True, reflection=True, diffraction=False, scattering=False, check_scene=False)
    a, tau = paths.cir(los=True, reflection=True, diffraction=False, scattering=False, ris=False)
    
    a = tf.squeeze(a)
    return 10 * tf.experimental.numpy.log10(ALPHA * tf.reduce_sum(tf.math.abs(a) ** 2, axis=1) / (k * T * B))

res = computeSNR(np.array([0, 0, 25 + GROUND_HEIGHT]))





# 4 Base Stations, 1 LoS and 1 Reflection each, so a 4x2 array
print(res.shape)
print(res)


# Which is Which?
for receiver in env.scene._receivers:
    print(env.scene.get(receiver).position)



